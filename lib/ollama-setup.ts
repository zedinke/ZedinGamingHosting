// Ollama automatikus be√°ll√≠t√°s helper
// Ez a f√°jl biztos√≠tja, hogy az Ollama el√©rhet≈ë legyen

const OLLAMA_URL = process.env.OLLAMA_URL || 'http://localhost:11434';
// Alap√©rtelmezett: llama3.2:3b - jobb magyar nyelv t√°mogat√°s, m√©g mindig gyors
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'llama3.2:3b';

export async function ensureOllamaReady(): Promise<boolean> {
  try {
    // Ellen≈ërzi, hogy az Ollama el√©rhet≈ë-e
    const response = await fetch(`${OLLAMA_URL}/api/tags`, {
      signal: AbortSignal.timeout(5000),
    });
    
    if (!response.ok) {
      return false;
    }

    // Ellen≈ërzi, hogy a modell let√∂ltve van-e
    const data = await response.json();
    const hasModel = data.models?.some(
      (m: any) => m.name === OLLAMA_MODEL || m.name.startsWith(`${OLLAMA_MODEL}:`)
    );

    if (!hasModel) {
      // Automatikusan let√∂lti a modellt
      console.log(`üì• Ollama modell let√∂lt√©se: ${OLLAMA_MODEL}...`);
      try {
        const pullResponse = await fetch(`${OLLAMA_URL}/api/pull`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            name: OLLAMA_MODEL,
            stream: false,
          }),
          signal: AbortSignal.timeout(300000), // 5 perc timeout a let√∂lt√©shez
        });

        if (pullResponse.ok) {
          console.log(`‚úÖ Ollama modell let√∂ltve: ${OLLAMA_MODEL}`);
          return true;
        }
      } catch (error) {
        console.error('Hiba a modell let√∂lt√©se sor√°n:', error);
        return false;
      }
    }

    return true;
  } catch (error) {
    console.error('Ollama el√©rhet≈ës√©gi hiba:', error);
    return false;
  }
}

